{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n",
      "Don't know how to reset  (), please run `%reset?` for details\n"
     ]
    }
   ],
   "source": [
    "reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.datasets import make_regression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Perceptron\n",
    "import ipympl\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import r2_score, classification_report, confusion_matrix, f1_score, precision_recall_curve, average_precision_score, roc_curve, auc\n",
    "%matplotlib widget\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carreguem el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "    d_train = pd.read_csv(path, header=0, delimiter=',')\n",
    "    return d_train\n",
    "\n",
    "os.getcwd()\n",
    "path = 'C:/Users/julia/Documents/JULIA/UNI/3r/kaggle/train_gr'\n",
    "os.chdir(path)\n",
    "os.getcwd()\n",
    "d_train = load_dataset('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train.insert(3, 'words', d_train[\"user_review\"].apply(lambda s: len(s.split())))\n",
    "d_train = d_train.drop(['review_id'], axis=1)\n",
    "d_train['title'] = [s.replace(\" \", \"\") for s in d_train['title']]\n",
    "d_train.insert(2, 'year_s', [str(s) for s in d_train['year']])\n",
    "d_train.insert(0, 'title_review', d_train['title'] + \" \" + d_train['year_s'] + \" \" + d_train[\"user_review\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separem els atributs de la X i l'atribut objectiu y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = d_train.values\n",
    "l = len(d_train.columns)\n",
    "X = data[:, 0]\n",
    "y = data[:, l-1]\n",
    "y = y.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funció per calcular el temps i la precisió d'un model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temps_score_model(clf, x_t, x_v, y_t, y_v):\n",
    "    inici = time.time()\n",
    "    clf = clf.fit(x_t, y_t)\n",
    "    fi = time.time()\n",
    "    print(\"Temps: \" + str(fi-inici))\n",
    "    print(\"Score: \" + str(clf.score(x_v, y_v)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separem les dades en test i validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t, x_v, y_t, y_v = train_test_split(X, y, train_size=0.8, stratify=y)\n",
    "vectorizer = CountVectorizer()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provem diferents models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps: 1.8811931610107422\n",
      "Score: 0.8656759074021149\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([('vect', vectorizer), ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(C=12.0, fit_intercept=True, penalty='l2', tol=0.1))])\n",
    "temps_score_model(clf, x_t, x_v, y_t, y_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps: 1.6740975379943848\n",
      "Score: 0.6418976850528723\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')  \n",
    "clf = Pipeline([('vect', vectorizer), ('tfidf', TfidfTransformer()),\n",
    "                ('clf', DecisionTreeClassifier(random_state=0, max_depth=2))])\n",
    "temps_score_model(clf, x_t, x_v, y_t, y_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps: 1.5243017673492432\n",
      "Score: 0.8248070877393541\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')  \n",
    "clf = Pipeline([('vect', vectorizer),('tfidf', TfidfTransformer()),\n",
    "                ('clf', Perceptron(tol=0.005, random_state=0))])\n",
    "temps_score_model(clf, x_t, x_v, y_t, y_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps: 1.4180030822753906\n",
      "Score: 0.7627893683909689\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')  \n",
    "clf = Pipeline([('vect', vectorizer), ('tfidf', TfidfTransformer()),\n",
    "                ('clf', KNeighborsClassifier(n_neighbors=3))])\n",
    "temps_score_model(clf, x_t, x_v, y_t, y_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps: 1.9787817001342773\n",
      "Score: 0.5973135181480423\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')  \n",
    "clf = Pipeline([('vect', vectorizer), ('tfidf', TfidfTransformer()),\n",
    "                ('clf', BaggingClassifier(KNeighborsClassifier(n_neighbors=3), max_samples=0.5, max_features=0.5))])\n",
    "temps_score_model(clf, x_t, x_v, y_t, y_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps: 12.230507135391235\n",
      "Score: 0.8042297799371249\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')  \n",
    "clf = Pipeline([('vect', vectorizer), ('tfidf', TfidfTransformer()),\n",
    "                ('clf', AdaBoostClassifier(n_estimators=100))])\n",
    "temps_score_model(clf, x_t, x_v, y_t, y_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps: 1.3908004760742188\n",
      "Score: 0.7999428408116604\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')  \n",
    "clf = Pipeline([('vect', vectorizer), ('tfidf', TfidfTransformer()),\n",
    "                ('clf', MultinomialNB(alpha=1.0))])\n",
    "temps_score_model(clf, x_t, x_v, y_t, y_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps: 1.4862914085388184\n",
      "Score: 0.8276650471563304\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')  \n",
    "clf = Pipeline([('vect', vectorizer), ('tfidf', TfidfTransformer()),\n",
    "                ('clf', ComplementNB())])\n",
    "temps_score_model(clf, x_t, x_v, y_t, y_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pels models que han tingut millor score trobem els millors hiperparàmetres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Millor c:     3.5\n",
      "Score màxim:  0.8628179479851386\n"
     ]
    }
   ],
   "source": [
    "maxi = 0\n",
    "l = [0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
    "for c in l:#range(1,20):\n",
    "    clf = Pipeline([('vect', vectorizer), ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(C=c, fit_intercept=True, penalty='l2', tol=0.1))])\n",
    "    clf = clf.fit(x_t, y_t)\n",
    "    m = clf.score(x_v, y_v)\n",
    "    if (m > maxi):\n",
    "        maxi = m\n",
    "        c_max = c\n",
    "print(\"Millor c:    \", c_max)\n",
    "print(\"Score màxim: \", maxi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Millor t:     0.1\n",
      "Score màxim:  0.8628179479851386\n"
     ]
    }
   ],
   "source": [
    "folds = 5\n",
    "maxi = 0\n",
    "l = [0.0001, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0]\n",
    "for t in l:\n",
    "    clf = Pipeline([('vect', vectorizer), ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(C=3.5, fit_intercept=True, penalty='l2', tol=t))])\n",
    "    clf = clf.fit(x_t, y_t)\n",
    "    m = clf.score(x_v, y_v)\n",
    "    if (m > maxi):\n",
    "        maxi = m\n",
    "        t_max = t\n",
    "print(\"Millor t:    \", t_max)\n",
    "print(\"Score màxim: \", maxi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ComplementNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Millor alpha:  1\n",
      "Score màxim:   0.8276650471563304\n"
     ]
    }
   ],
   "source": [
    "maxi = 0\n",
    "l = [0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
    "for c in range(1,20):\n",
    "    clf = Pipeline([('vect', vectorizer), ('tfidf', TfidfTransformer()),\n",
    "                ('clf', ComplementNB(alpha=c))])\n",
    "    clf = clf.fit(x_t, y_t)\n",
    "    m = clf.score(x_v, y_v)\n",
    "    if (m > maxi):\n",
    "        maxi = m\n",
    "        c_max = c\n",
    "print(\"Millor alpha: \", c_max)\n",
    "print(\"Score màxim:  \", maxi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Millor tol:   0.01\n",
      "Score màxim:  0.827950843098028\n"
     ]
    }
   ],
   "source": [
    "maxi = 0\n",
    "l = [0.0001, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0]\n",
    "for c in l:\n",
    "    clf = Pipeline([('vect', vectorizer), \n",
    "                   ('tfidf', TfidfTransformer()),\n",
    "                   ('clf', Perceptron(tol=c, random_state=0)),\n",
    "                   ])\n",
    "    clf = clf.fit(x_t, y_t)\n",
    "    m = clf.score(x_v, y_v)\n",
    "    if (m > maxi):\n",
    "        maxi = m\n",
    "        c_max = c\n",
    "print(\"Millor tol:  \", c_max)\n",
    "print(\"Score màxim: \", maxi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
